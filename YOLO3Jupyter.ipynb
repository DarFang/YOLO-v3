{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV's Capture Feature\n",
    "First, let's make a program that captures the feedback of the camera and displays it in a new window.\n",
    "\n",
    "\n",
    "The variable 'capture' is the webcam device. The parameters inside 'cv.VideoCapture()' can either take a video in the same directory of the code if the parameter the string of that file name, or a live video such as the webcam if the parameter is an integer (generally 0). I am using 1 since I want to use my other webcam.\n",
    "\n",
    "The following will be in a loop:\n",
    "\n",
    "The variable 'frame' takes a frame of that webcam from the function 'capture.read()'\n",
    "\n",
    "The function 'cv.imshow()' now displays that frame on another window. The parameters inputted are the title that will be shown in the new window, and the displayed 'frame'.\n",
    "\n",
    "The function 'cv.waitKey()' tells the program to wait for that long. If it is set to 0, it will wait infinitely. The value 27 is the 'esc' key.\n",
    "\n",
    "To exit the program, press the 'esc' key\n",
    "\n",
    "The last two functions 'capture.release()' and 'cv.destroyAllWindows()' just closes the windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# Integer for live camera, or string for file\n",
    "capture = cv.VideoCapture(0) \n",
    "while True:\n",
    "    # 'isTrue' is a boolen if it successfuly captured something\n",
    "    # 'frame' is the frame of the video\n",
    "    isTrue, frame = capture.read() \n",
    "    # 'imshow' function makes a new window\n",
    "    cv.imshow('Webcam', frame)\n",
    "    if cv.waitKey(1) == 27: # Break while loop using esc\n",
    "        break\n",
    "    # Close \n",
    "capture.release() \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import our Class IDs\n",
    "Next is to import the file that will be consisting of our weights, config, and names. The weight and config determine if a portion of the image is potentially an identified object. Since we are using YOLO, we will be using the coco set consisting of 80 common objects like 'person', 'cup', 'cell phone', etc. The weights themselves are indexed and do not have a name associated with that index, so we will be making that below.\n",
    "\n",
    "We will first open the text file name 'coco.names' using 'with open() as f' with the first parameter being the file name and the second parameter being the read type. The variable classNames will store a list consisting of the names in the correct index.'f.read()' just reads the whole file as a string, then '.split' splits the string into a list separated by the newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text file of names\n",
    "importClassNames = 'coco.names'\n",
    "# List\n",
    "classNames = []\n",
    "# File to list\n",
    "with open(importClassNames, 'r') as f: \n",
    "    classNames = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', '']\n"
     ]
    }
   ],
   "source": [
    "print(classNames) #check the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Machine Learning Algorithm\n",
    "Next, we will create the machine learning algorithm using the two files found on this website. We will be using the variable 'net' later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# File for the config\n",
    "modelConfiguation = 'yolov3.cfg' \n",
    "# File for the weights of the objects(this is already pretrained)\n",
    "modelWeights = 'yolov3.weights'  \n",
    "# Creating the network of nodes to compare input and outputs\n",
    "# Machine learning algorithm\n",
    "net = cv.dnn.readNet(modelConfiguation, modelWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting 'frame' to be Used in the Algorithm\n",
    "Right now the picture cannot be processed in the machine learning algorithm, So we will convert the frame into something called a 'blob'. Blob takes in a few parameters: image, scale factor, size, mean, swap RB, crop. We will then send the input of the blob into the network. The 'layerNames' variable gets all the variable names of our layers in the network. \n",
    "\n",
    "Next, we have to extract the output layers using the function 'network.getUnconnectedOutlayers()'. Note that we are just getting the index of the output, so we will use the index and refer it back to the 'layerNames'. Next, we will make a variable that forwards the outputNames to the network using the function 'net.forward'.\n",
    "\n",
    "Now the network has a bunch of values including the bounding box, as well as its percentages, so the next part of the programs start filtering those results to be displayed later\n",
    "\n",
    "Since the output does not use the index '0' and starts the index at 1, we will shift the index by '-1'.\n",
    "Outputs will be the results we will need to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getOutputs(frame):\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (widthheight, widthheight), [0, 0, 0], 1, crop = False)\n",
    "    # network is where all the magic happens\n",
    "    # it just tells gives you outputs for objects on the screen\n",
    "    net.setInput(blob)\n",
    "    layerNames = net.getLayerNames() #gets all names of the layer\n",
    "    #print(layerNames)\n",
    "    #print(net.getUnconnectedOutLayers()) #this gets the index of the output (does not use '0')\n",
    "    outputNames = [layerNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    #print(outputNames)\n",
    "    #send image to network, find output\n",
    "    outputs = net.forward(outputNames) # output is a list containing 3 values, within the list 'numpy'\n",
    "    #print(len(outputs))         # 3\n",
    "    #print(type(outputs))        # list\n",
    "    #print(type(outputs[0]))     # numpy.ndarray (matrix)\n",
    "    #print(outputs[0].shape)      # (300, 85 )\n",
    "    #print(outputs[0][0])\n",
    "    #print(outputs[1].shape)      # (1200, 85)\n",
    "    #print(outputs[2].shape)      # (4800, 85)\n",
    "    # for each box number, center x, center y, width, height, confidence object present, rest probability of that class\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating What to be Displayed\n",
    "Now that we have the results, we will now make an algorithm to display the highest probability of that object in the bounding box. First, note that the output consists of 85 values instead of 80 from our name list. The first 5 values are as followed: center x, center y, width, height, confidence object present. The rest of the 80 values are the probability of that object displayed. We will make a new variable 'scores' consisting of only the probability of those objects. We will then get the class ID of the max probability of that object. We will also get that probability value by finding the index of the scores. \n",
    "\n",
    "The next thing is to check if the probability of that object is higher than our threshold. If it is we will make a bounding box for it. To make a bounding box, we will need 4 variables: x and y coordinate, the width, and the height of the bounding box. The code below edits the center x and y coordinate to the respective coordinate.\n",
    "The variable 'outputBox' removes uneccesary boxes, and this is controlled by the variable 'nmsThreshold'.We will finaly display the boxes to the window using 'cv.rectangle()', 'cv.putText()', 'cv.imshow()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def displayBox(outputs):\n",
    "    height, width, channels = frame.shape  # get the values of the h, w, channel is not needed\n",
    "    boundingBox = []   # creates a list of bounding boxes to be created\n",
    "    classIDs = []      # gets the id of the list\n",
    "    confidenceValues = []   # gets the confident value\n",
    "    \n",
    "    for output in outputs:\n",
    "        for values in output:  # values contains values and predictables\n",
    "            scores = values[5:] # only contains the values of the predictions\n",
    "            classID = np.argmax(scores)  #gets the class ID with the highest score within the list\n",
    "            confidence = scores[classID] #gets the confidence value\n",
    "            if confidence > confidenceThreshold:  #checks if it passes the threshold\n",
    "                w, h = int(values[2] * width), int(values[3] * height) # width and height of bounding box\n",
    "                x, y = int(values[0] * width - w/2), int(values[1] * height - h/2)  # get the x y position\n",
    "                boundingBox.append([x, y, w, h])  # add bounding box\n",
    "                classIDs.append(classID) # add classids\n",
    "                confidenceValues.append(float(confidence)) # add confidence value\n",
    "    \n",
    "    #removes inside boxes , based on nms threshold\n",
    "    outputBox = cv.dnn.NMSBoxes(boundingBox, confidenceValues, confidenceThreshold, nmsThreshold)\n",
    "            #gets a nested list    \n",
    "    for i in outputBox:\n",
    "        index = i[0]\n",
    "        color = colors[classIDs[index]]\n",
    "        x, y, w, h = boundingBox[index][:4]\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        #(image, point 1, point 2, color, thickness)\n",
    "        cv.putText(frame, f'{classNames[classIDs[index]].capitalize()} {int(confidenceValues[index] * 100)}%',\n",
    "                   (x,y-10), font, 0.6, color, 2)\n",
    "        #(image, text, position, font, size, color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "Finally we will add the features to the original capture feature we have made earlier with some constants that we can change later if we felt like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "widthheight = 320             # used to evaluated the image at that pixel\n",
    "confidenceThreshold = 0.5     # value that tells you the threshold of how the network sees as that object\n",
    "nmsThreshold = 0.6            # value is used to decrease the number of bounding boxes displayed\n",
    "font = cv.FONT_HERSHEY_SIMPLEX# font value for output name\n",
    "colors = np.random.uniform(0, 255, size = (len(classNames),3)) # option for using different colors for every name\n",
    "capture = cv.VideoCapture(1) #use webcam with integer, or path\n",
    "while True:\n",
    "    ifTrue, frame = capture.read()\n",
    "    #network understands blob\n",
    "    #outputs = getOutputs(frame)\n",
    "    displayBox(getOutputs(frame))\n",
    "    cv.imshow('cam', frame)\n",
    "    if cv.waitKey(1) == 27: #break while loop\n",
    "        break\n",
    "capture.release() # close\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
